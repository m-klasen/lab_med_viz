{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e37acd4-f537-4b81-96f1-dc445f71921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spottunet.dataset.cc359 import *\n",
    "from spottunet.split import one2all, single_cv\n",
    "from spottunet.torch.module.unet import UNet2D\n",
    "from spottunet.utils import sdice\n",
    "from dpipe.im.metrics import dice_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler \n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from monai import transforms as T\n",
    "from monai.transforms import Compose, apply_transform\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "import json\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from dpipe.im.shape_ops import zoom\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainer import Trainer\n",
    "from dataset.loader import *\n",
    "\n",
    "import wandb\n",
    "from configs.config import CFG\n",
    "from utils import *\n",
    "\n",
    "def class2dict(f):\n",
    "    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "def class2str(f):\n",
    "    return [[name, getattr(f, name)] for name in dir(f) if not name.startswith('__')]\n",
    "\n",
    "def write_config(CFG):\n",
    "    with open(f\"{CFG.results_dir}/config.txt\", \"w\") as f:\n",
    "        for n,v in class2str(CFG):\n",
    "            f.write(f\"{n}={v} \\n\")\n",
    "    f.close()\n",
    "    \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from dataset.dataloader import *\n",
    "from dataset.loader import PrefetchLoader, fast_collate\n",
    "from dataset.dataloader_utils import *\n",
    "\n",
    "from dataset.mixup import FastCollateMixup\n",
    "from dataset.augment import get_transforms, get_test_transforms\n",
    "\n",
    "from scheduler import LinearWarmupCosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e077bff-42c9-4ac1-ac5c-fd1a4cf19b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"baseline_results/baseline_focal_lovasz_adam_rand_aug_default_v1\",\n",
    "    \"baseline_results/baseline_focal_lovasz_Adam_rand_aug_default_frontback\",\n",
    "    \"baseline_results/baseline_focal_lovasz_adam_rand_aug_default_sideview\",\n",
    "    ]\n",
    "views = [\n",
    "        (2,0,1),\n",
    "        (1,0,2),\n",
    "        (0,1,2)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c006c1a-482f-474a-aad3-8d0fb4344323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_fold(fold):\n",
    "    slice_index=130\n",
    "    CFG.transpose = (0,1,2)\n",
    "    CFG.fcm_mask = None\n",
    "    output_dir =  \"predictions/baseline_focal_lovasz_multiview_ensemble_v2/\" + f\"/mode_{fold}/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    cc359_df = pd.read_csv(f\"{CFG.dataset_path}/meta.csv\",delimiter=\",\")\n",
    "\n",
    "    model = UNet2D(n_chans_in=CFG.n_chans_in, n_chans_out=CFG.n_chans_out, n_filters_init=CFG.n_filters)\n",
    "    model.to(CFG.device)\n",
    "\n",
    "\n",
    "    seed = 0xBadCafe\n",
    "    val_size = 4\n",
    "    n_experiments = len(cc359_df.fold.unique())\n",
    "    split = one2all(df=cc359_df,val_size=val_size)[:n_experiments]\n",
    "\n",
    "    test_df  = cc359_df.iloc[split[fold][2]].reset_index()\n",
    "\n",
    "    test_dataset = CC359_Dataset(CFG,df=test_df,root_dir=CFG.dataset_path,\n",
    "                                 voxel_spacing=CFG.voxel_spacing,transforms=get_test_transforms(),\n",
    "                                 mode=\"test\", cache=False, td_specific_aug=False)\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset, \n",
    "                                  batch_size=1,shuffle=False,\n",
    "                                  num_workers=0,pin_memory = False)\n",
    "\n",
    "    model.eval()\n",
    "    import copy\n",
    "    results = defaultdict(dict)\n",
    "    for step,(x,y,_id) in progress_bar(enumerate(test_dataloader, 1), len(test_dataloader)):\n",
    "        _id=_id[0]\n",
    "        with torch.no_grad():\n",
    "            all_logits = []\n",
    "            if _id==\"CC0002\":\n",
    "                for m,v in zip(models,views):\n",
    "                    model.load_state_dict(torch.load(f\"{m}/mode_{fold}/e_39.pth\")[\"model_state_dict\"])\n",
    "                    x_c, y_c = copy.deepcopy(x.squeeze()), copy.deepcopy(y.squeeze())\n",
    "                    x_c = torch.permute(x_c,v)\n",
    "                    y_c = torch.permute(y_c,v)\n",
    "                    x_c = x_c.to(CFG.device)\n",
    "                    c,h,w = x_c.shape\n",
    "                    logits = model(x_c.unsqueeze(1))\n",
    "                    logits = logits.squeeze().sigmoid().cpu().detach().numpy()\n",
    "                    all_logits.append(logits)\n",
    "                    outputs = (logits > .5)\n",
    "                    \"\"\"surface_dice = sdice(y_c.squeeze().numpy().astype(bool), outputs, CFG.voxel_spacing,CFG.sdice_tolerance)\n",
    "                    fig, (ax, bx, cx, dx) = plt.subplots(1,4, figsize=(20,5))\n",
    "                    inp = ax.imshow(x_c[slice_index].cpu().numpy())\n",
    "                    #ax.set_title(str(tta))\n",
    "                    fig.colorbar(inp, ax=ax)\n",
    "                    bx.imshow(outputs[slice_index])\n",
    "                    bx.set_title(str(round(surface_dice, 4)))\n",
    "                    cx.imshow(y_c[slice_index].squeeze())\n",
    "                    dx.imshow(y_c[slice_index].squeeze()-outputs[slice_index])\n",
    "                    plt.show()\"\"\"\n",
    "                td_view = all_logits[0]\n",
    "                fb_view = np.transpose(all_logits[1], (2,1,0))\n",
    "                lr_view = np.transpose(all_logits[2], (2,0,1))\n",
    "                y = np.transpose(y.squeeze(), (2,0,1))\n",
    "\n",
    "                total_logits_mean = np.mean([td_view,fb_view,lr_view], axis=0)\n",
    "                total_outputs = (total_logits_mean > .5)\n",
    "                surface_dice = sdice(y.squeeze().numpy().astype(bool), total_outputs, CFG.voxel_spacing,CFG.sdice_tolerance)\n",
    "\n",
    "                results['sdice_score'][_id] = surface_dice\n",
    "                results['dice_score'][_id]  = dice_score(y.squeeze().numpy().astype(bool), total_outputs)\n",
    "                \"\"\"fig, (ax, bx, cx, dx) = plt.subplots(1,4, figsize=(20,5))\n",
    "                inp = ax.imshow(x_c[slice_index].cpu().numpy())\n",
    "                fig.colorbar(inp, ax=ax)\n",
    "                bx.imshow(td_view[slice_index])\n",
    "                cx.imshow(fb_view[slice_index])\n",
    "                dx.imshow(lr_view[slice_index])\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "\n",
    "                print(total_outputs.shape)\n",
    "\n",
    "                fig, (ax, bx, cx, dx) = plt.subplots(1,4, figsize=(20,5))\n",
    "                inp = ax.imshow(x_c[slice_index].cpu().numpy())\n",
    "                fig.colorbar(inp, ax=ax)\n",
    "                bx.imshow(total_outputs[slice_index])\n",
    "                bx.set_title(str(round(surface_dice, 4)))\n",
    "                cx.imshow(y[slice_index])\n",
    "                plt.show()\"\"\"\n",
    "                print(_id+str(surface_dice))\n",
    "                np.save(output_dir+f\"/{_id}.npy\",outputs)\n",
    "\n",
    "    with open(os.path.join(output_dir, 'sdice_score' + '.json'), 'w') as f:\n",
    "        json.dump(results['sdice_score'], f, indent=0)\n",
    "    with open(os.path.join(output_dir, 'dice_score'+ '.json'), 'w') as f:\n",
    "        json.dump(results['dice_score'], f, indent=0)\n",
    "        \n",
    "        \n",
    "for fold in [3,1,2,3,4,5]:\n",
    "    run_fold(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d69d0-93f3-45cb-a355-6e49f6bf6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"oracle_results/focal_lovasz_adam_rand_aug_default\",\n",
    "    \"oracle_results/focal_lovasz_adam_rand_aug_default_frontview\",\n",
    "    \"oracle_results/focal_lovasz_adam_rand_aug_default_sideview\",\n",
    "    ]\n",
    "views = [\n",
    "        (2,0,1),\n",
    "        (1,0,2),\n",
    "        (0,1,2)\n",
    "        ]\n",
    "\n",
    "def run_fold(fold):\n",
    "    slice_index=130\n",
    "    CFG.transpose = (0,1,2)\n",
    "    output_dir =  \"oracle_results/baseline_focal_lovasz_multiview_ensemble/\" + f\"/mode_{fold}/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    cc359_df = pd.read_csv(f\"{CFG.dataset_path}/meta.csv\",delimiter=\",\")\n",
    "\n",
    "    model = UNet2D(n_chans_in=CFG.n_chans_in, n_chans_out=CFG.n_chans_out, n_filters_init=CFG.n_filters)\n",
    "    model.to(CFG.device)\n",
    "\n",
    "\n",
    "    seed = 0xBadCafe\n",
    "    n_splits = 3\n",
    "    val_size = 2\n",
    "    split = single_cv(cc359_df, n_splits=n_splits, val_size=val_size, seed=seed) \n",
    "\n",
    "\n",
    "    train_df = cc359_df.iloc[split[fold][0]].reset_index()\n",
    "    valid_df = cc359_df.iloc[split[fold][1]].reset_index()\n",
    "    test_df  = cc359_df.iloc[split[fold][2]].reset_index()\n",
    "\n",
    "\n",
    "    test_df  = cc359_df.iloc[split[fold][2]].reset_index()\n",
    "\n",
    "    test_dataset = CC359_Dataset(CFG,df=test_df,root_dir=CFG.dataset_path,\n",
    "                                 voxel_spacing=CFG.voxel_spacing,transforms=get_test_transforms(),\n",
    "                                 mode=\"test\", cache=False)\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset, \n",
    "                                  batch_size=1,shuffle=False,\n",
    "                                  num_workers=0,pin_memory = False)\n",
    "\n",
    "    model.eval()\n",
    "    import copy\n",
    "    results = defaultdict(dict)\n",
    "    for step,(x,y,_id) in progress_bar(enumerate(test_dataloader, 1), len(test_dataloader)):\n",
    "        _id=_id[0]\n",
    "        with torch.no_grad():\n",
    "            all_logits = []\n",
    "            for m,v in zip(models,views):\n",
    "                model.load_state_dict(torch.load(f\"{m}/mode_{fold}/e_39.pth\")[\"model_state_dict\"])\n",
    "                x_c, y_c = copy.deepcopy(x.squeeze()), copy.deepcopy(y.squeeze())\n",
    "                x_c = torch.permute(x_c,v)\n",
    "                y_c = torch.permute(y_c,v)\n",
    "                x_c = x_c.to(CFG.device)\n",
    "                c,h,w = x_c.shape\n",
    "                logits = model(x_c.unsqueeze(1))\n",
    "                logits = logits.squeeze().sigmoid().cpu().detach().numpy()\n",
    "                all_logits.append(logits)\n",
    "                outputs = (logits > .5)\n",
    "\n",
    "            td_view = all_logits[0]\n",
    "            fb_view = np.transpose(all_logits[1], (2,1,0))\n",
    "            lr_view = np.transpose(all_logits[2], (2,0,1))\n",
    "            y = np.transpose(y.squeeze(), (2,0,1))\n",
    "\n",
    "            total_logits_mean = np.mean([td_view,fb_view,lr_view], axis=0)\n",
    "            total_outputs = (total_logits_mean > .5)\n",
    "            surface_dice = sdice(y.squeeze().numpy().astype(bool), total_outputs, CFG.voxel_spacing,CFG.sdice_tolerance)\n",
    "\n",
    "            results['sdice_score'][_id] = surface_dice\n",
    "            results['dice_score'][_id]  = dice_score(y.squeeze().numpy().astype(bool), total_outputs)\n",
    "\n",
    "    with open(os.path.join(output_dir, 'sdice_score' + '.json'), 'w') as f:\n",
    "        json.dump(results['sdice_score'], f, indent=0)\n",
    "    with open(os.path.join(output_dir, 'dice_score'+ '.json'), 'w') as f:\n",
    "        json.dump(results['dice_score'], f, indent=0)\n",
    "        #np.save(output_dir+f\"/{_id}.npy\",outputs)\n",
    "        \n",
    "for fold in range(0,18):\n",
    "    run_fold(fold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch1.9] *",
   "language": "python",
   "name": "conda-env-torch1.9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
