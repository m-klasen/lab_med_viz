{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf986d6-5678-4dc7-bc6e-532713902547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib widget\n",
    "from spottunet.dataset.cc359 import Rescale3D, CC359, scale_mri\n",
    "from dpipe.dataset.wrappers import apply, cache_methods\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "import nibabel as nib\n",
    "from matplotlib import animation, rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "\n",
    "def create_animation(ims):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.axis('off')\n",
    "    im = plt.imshow(ims[0], cmap=\"gray\")\n",
    "\n",
    "    def animate_func(i):\n",
    "        im.set_array(ims[i])\n",
    "        return [im]\n",
    "\n",
    "    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000//24)\n",
    "\n",
    "\n",
    "\n",
    "data_path=\"/home/mlk/cc359\"\n",
    "voxel_spacing=[1, 0.95, 0.95]\n",
    "df = pd.read_csv(\"meta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0efca6-4f36-4f6a-a5e4-c0f0269dd4b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Paper dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb216c5-58dc-4ec8-bb5f-7b5e0dff1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpipe.batch_iter import Infinite, load_by_random_id, unpack_args, multiply\n",
    "from dpipe.im.shape_utils import prepend_dims\n",
    "from spottunet.batch_iter import slicewise, SPATIAL_DIMS, get_random_slice, extract_patch, sample_center_uniformly\n",
    "\n",
    "preprocessed_dataset = apply(Rescale3D(CC359(data_path), voxel_spacing), load_image=scale_mri)\n",
    "dataset = apply(preprocessed_dataset, load_image=np.float32)\n",
    "\n",
    "load_x = dataset.load_image\n",
    "load_y = dataset.load_segm\n",
    "\n",
    "ids_sampling_weights = None\n",
    "slice_sampling_interval = 1\n",
    "seed = 0xBadCafe\n",
    "x_patch_size = y_patch_size = np.array([256, 256])\n",
    "batch_size = 32\n",
    "batches_per_epoch = 100\n",
    "\n",
    "def get_random_patch_2d(image_slc, segm_slc, x_patch_size, y_patch_size):\n",
    "    sp_dims_2d = (-2, -1)\n",
    "    center = sample_center_uniformly(segm_slc.shape, y_patch_size, sp_dims_2d)\n",
    "    x, y = extract_patch((image_slc, segm_slc, center), x_patch_size, y_patch_size, spatial_dims=sp_dims_2d)\n",
    "    return x, y\n",
    "\n",
    "x = load_by_random_id(dataset.load_image, dataset.load_segm, ids=df['id'],\n",
    "                      weights=ids_sampling_weights, random_state=seed),\n",
    "x,y = next(x[0])\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "plt.imshow(x[75])\n",
    "plt.show()\n",
    "plt.imshow(y[75])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "scaled_x = (x*255).astype(np.uint8)\n",
    "scaled_x = scaled_x / 255.\n",
    "\n",
    "\n",
    "diff = scaled_x[75]-x[75]\n",
    "plt.imshow(diff)\n",
    "plt.show()\n",
    "print(diff.min(), diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47950a3-af81-42a7-aa00-a12182f6ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.array([[534.57594992, 342.57558555],\n",
    " [530.33945514, 400.71141039],\n",
    " [542.48652573, 444.98639819],\n",
    " [547.99561513, 378.95523483],\n",
    " [423.66897131, 338.37503833],\n",
    " [423.57189916, 395.56296789],\n",
    " [418.43571045, 438.0447123 ],\n",
    " [418.32133933, 373.22089059]])\n",
    "\n",
    "image_shape = [480,848]\n",
    "minxy = np.min(arr,axis=0) #axis=1\n",
    "print(\"minxy: \"+str(minxy))\n",
    "# box_corners_in_image: [N, 8, 2]\n",
    "maxxy = np.max(arr,axis=0) #war box_corners_in_image), axis=1\n",
    "print(\"maxxy: \"+str(maxxy))\n",
    "#bbox = np.concatenate([minxy, maxxy]) #axis = 1\n",
    "bbox = np.stack((minxy, maxxy), axis=1)\n",
    "print(\"bbox: \"+str(bbox))\n",
    "\n",
    "bbox[2:] = np.minimum(bbox[2:], image_shape[::-1])\n",
    "bbox[:2] = np.maximum(bbox[:2], [0, 0])\n",
    "print(\"bbox mit neuem min und max: \"+str(bbox[j]))\n",
    "anno[\"bbox\"].append(bbox)\n",
    "anno[\"alpha\"].append(\n",
    "    -np.arctan2(-final_box_preds[j, 1], final_box_preds[j, 0])\n",
    "    + box3d_pts_2d[j, 6]\n",
    ")\n",
    "# anno[\"dimensions\"].append(box3d_camera[j, [4, 5, 3]])\n",
    "anno[\"dimensions\"].append(box3d_pts_2d[j, 3:6])\n",
    "anno[\"location\"].append(box3d_pts_2d[j, :3])\n",
    "anno[\"rotation_y\"].append(box3d_pts_2d[j, 6])\n",
    "anno[\"name\"].append(class_names[int(label_preds[j])])\n",
    "anno[\"truncated\"].append(0.0)\n",
    "anno[\"occluded\"].append(0)\n",
    "anno[\"score\"].append(scores[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f42972-6800-4f15-8649-67eab9de54b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, inputs in enumerate(iterator()):\n",
    "    print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125a8af5-330a-4eac-8953-1dfd642c5389",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx in df['id']:\n",
    "    img_1 = preprocessed_dataset.load_spacing(idx)\n",
    "    print(idx,img_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3bc4ba-46f9-49a8-9f4d-9a785cd24b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Viz Learning rate scheduler\n",
    "\n",
    "from conf import CFG\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import MultiplicativeLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "optimizer = CFG.optim([torch.tensor(1)],lr=CFG.lr,weight_decay=CFG.wd)\n",
    "\n",
    "scheduler = MultiplicativeLR(optimizer, lr_lambda=lambda epoch: 0.96, )\n",
    "lrs = []\n",
    "for e in range(100):\n",
    "    optimizer.step()\n",
    "    lrs.append(scheduler.get_lr())\n",
    "    scheduler.step()\n",
    "\n",
    "plt.plot(lrs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a718bf9-7398-4c0d-85cb-915d609bb3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = preprocessed_dataset.load_image(\"CC0030\")\n",
    "seg_1 = preprocessed_dataset.load_segm(\"CC0030\")\n",
    "\n",
    "out = np.zeros((150,269,269*2))\n",
    "out[:,:,:269] = img_1\n",
    "out[:,:,269:] = seg_1\n",
    "create_animation(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d68c2-ee92-44a6-90c2-a03980b65455",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = preprocessed_dataset.load_image(\"CC0201\")\n",
    "    seg_1 = preprocessed_dataset.load_segm(\"CC0201\")\n",
    "\n",
    "    c,h,w = img_1.shape\n",
    "    out = np.zeros((c,h,w*2))\n",
    "    out[:,:,:269] = img_1\n",
    "    out[:,:,269:] = seg_1\n",
    "    create_animation(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e80a31-de43-41a5-bbad-8d0493234785",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in df['id']:\n",
    "    img_1 = preprocessed_dataset.load_image(idx)\n",
    "    seg_1 = preprocessed_dataset.load_segm(idx)\n",
    "\n",
    "    c,h,w = img_1.shape\n",
    "    out = np.zeros((c,h,w*2))\n",
    "    out[:,:,:w] = img_1\n",
    "    out[:,:,w:] = seg_1\n",
    "    ani = create_animation(out)\n",
    "    FFwriter = animation.FFMpegWriter(fps=10)\n",
    "    ani.save(f'dataset_viz/{idx}.mp4', writer = FFwriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe074b7-dd05-4e94-ada4-426e9ecdd753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['id']==\"CC0326\"]['tomograph_model'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adacad3c-f198-4f09-9d98-127f79622b8d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "for idx in df['id']:\n",
    "    print(idx)\n",
    "    img_1 = preprocessed_dataset.load_image(idx)\n",
    "    seg_1 = preprocessed_dataset.load_segm(idx)\n",
    "    img_1 = np.transpose(img_1,(2,0,1))\n",
    "    seg_1 = np.transpose(seg_1,(2,0,1))\n",
    "    model = df[df['id']==idx]['tomograph_model'].values[0]\n",
    "    tsla  = df[df['id']==idx]['tesla_value'].values[0]\n",
    "    c,h,w = img_1.shape\n",
    "    out = np.zeros((1,h,w*2))\n",
    "    out[:,:,:w] = img_1[c//2]\n",
    "    out[:,:,w:] = seg_1[c//2]\n",
    "    #plt.figure(figsize=(20,10))\n",
    "    #plt.imshow(out.squeeze())\n",
    "    fn_out = f'dataset_plots3/{idx}_{model}-{str(tsla)}.jpg'\n",
    "    print(fn_out,  out.shape)\n",
    "    cv2.imwrite(fn_out,(out*255).astype(np.uint8).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd63f02-7c88-4f3a-9f94-4c032efdf64f",
   "metadata": {},
   "source": [
    "### Custom dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd59025-a174-40a2-872a-c6a100936699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spottunet.dataset.cc359 import *\n",
    "from spottunet.split import one2all\n",
    "from spottunet.torch.module.unet import UNet2D\n",
    "from spottunet.utils import sdice\n",
    "from dpipe.im.metrics import dice_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler \n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from monai import transforms as T\n",
    "from monai.transforms import Compose, apply_transform\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "import json\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from dpipe.im.shape_ops import zoom\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c8ec1-a0de-4679-b457-f09adb2acf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.augment import augment_transform\n",
    "\n",
    "hparams = dict(\n",
    "            translate_const=int(256 * 0.020),\n",
    "            img_mean=tuple([0]),\n",
    "            )\n",
    "\n",
    "aug = augment_transform([\"TranslateXRel\"],\"rand-m9-mstd0.5\",hparams)\n",
    "aug(Image.fromarray(np.zeros((3,256,256),dtype=np.uint8), mode=\"RGB\"),Image.fromarray(np.zeros((3,256,256),dtype=np.uint8), mode=\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873c3bb-a70f-4357-958e-6024b6ee5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sgd = torch.load(\"/media/mlk/New Volume/Lab/domain_shift_anatomy/dart_results/baseline_default/experiment_3/model.pth\", map_location=\"cpu\")\n",
    "adam = torch.load(\"baseline_results/baseline_focal_lovasz_adam_rand_aug_default_v1/mode_3/e_39.pth\", map_location=\"cpu\")['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8d5980-4411-49fd-a3cd-a5734c727846",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sgd.keys():\n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "    plt.title(k)\n",
    "    sns.histplot(np.array(sgd[k]).reshape(-1), ax=axes[0], )\n",
    "    sns.histplot(np.array(adam[k]).reshape(-1), ax=axes[1], )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feb20ab-65c1-46d5-a562-769e7a4d37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(np.array(sgd['init_path.1.conv_path.0.bn.weight']).reshape(-1))\n",
    "plt.show()\n",
    "sns.histplot(np.array(adam['init_path.1.conv_path.0.bn.weight']).reshape(-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d48d6-c2ed-4a0e-88bc-910b26dc1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "sns.violinplot(data=[np.array(sgd['init_path.1.conv_path.0.bn.weight']).reshape(-1),np.array(adam['init_path.1.conv_path.0.bn.weight']).reshape(-1)])\n",
    "sns.despine(offset=10, trim=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf2343-b320-433c-8eac-47fe77ff5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa7577f-6b09-4db3-88fb-4eb4b0a91319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _grid_distortion_level_to_arg(level, _hparams):\n",
    "    level = (level / (10.+1)) * 0.5\n",
    "    return level,\n",
    "\n",
    "_grid_distortion_level_to_arg(random.gauss(9, 0.5),None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe8d7c-8dc4-4fa6-8be8-90846c9c2ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intensity_normalization.normalize.fcm import FCMNormalize\n",
    "import glob\n",
    "\n",
    "for fn, fn_brain_mask in zip(sorted(glob.glob(f\"{CFG.dataset_path}/images_scaled_voxel_spacing/*\")),\n",
    "                             sorted(glob.glob(f\"{CFG.dataset_path}/robex_masks_svsp/*\"))):\n",
    "\n",
    "    #fn = f\"{CFG.dataset_path}/images_scaled_voxel_spacing/CC0001_philips_15_55_M.nii.gz\"\n",
    "    #fn_brain_mask = f\"{CFG.dataset_path}/robex_masks_svsp/CC0001_philips_15_55_M.nii.gz\"\n",
    "    fcm_norm = FCMNormalize(tissue_type=\"csf\")\n",
    "    file = nib.load(fn)\n",
    "    file_mask = nib.load(fn_brain_mask)\n",
    "\n",
    "    normed_file = fcm_norm(file,file_mask)\n",
    "    \n",
    "    outfile = fn.replace(\"images_scaled_voxel_spacing\", \"fcm_norm_csf\")\n",
    "    nib.save(normed_file, outfile)\n",
    "    \n",
    "    tissue_membership = nib.Nifti1Image(\n",
    "                fcm_norm.tissue_membership,\n",
    "                normed_file.affine,\n",
    "                normed_file.header,\n",
    "            )\n",
    "    outfile_tissue_membership = outfile[:-7] + 'csf_membership' + outfile[-7:]\n",
    "    tissue_membership.to_filename(outfile_tissue_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b60eebb-d5de-48fb-ad0c-b294bde69b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fcm_norm.tissue_membership[130])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f3633-05ab-4d50-8d5c-d2b8275ce937",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from configs.config import CFG\n",
    "from dataset.dataloader import *\n",
    "from dataset.dataloader_utils import *\n",
    "from dataset.augment import get_transforms, get_test_transforms\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "cc359_df = pd.read_csv(f\"{CFG.dataset_path}/meta.csv\",delimiter=\",\")\n",
    "train_dataset = CC359_Dataset(CFG,df=cc359_df,root_dir=CFG.dataset_path,\n",
    "                                  voxel_spacing=CFG.voxel_spacing,transforms=None,#get_transforms(\"default\"),\n",
    "                                  mode=\"test\", cache=False,)\n",
    "cc359_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ed92c-01ff-406e-81b7-5979e775a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dpipe.io import load\n",
    "path_base = Path('baseline_results/baseline_lovasz_default')\n",
    "\n",
    "meta = pd.read_csv(f\"meta.csv\",delimiter=\",\", index_col='id')\n",
    "meta.head()\n",
    "\n",
    "all_sdices = []\n",
    "for s in sorted(cc359_df['fold'].unique()):\n",
    "    sdices = load(path_base / f'mode_{s}/sdice_score.json')\n",
    "    all_sdices.append(sdices)\n",
    "\n",
    "def id_to_scanner(id):\n",
    "    df = cc359_df[cc359_df['id']==id]\n",
    "    return df['tomograph_model'].values[0] + str(df['tesla_value'].values[0])\n",
    "test = \"CC0231\"\n",
    "id_to_scanner(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b55952-557b-4e53-816c-592828067b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.rand_augment import *\n",
    "\n",
    "_RAND_TRANSFORMS = [\n",
    "    'AutoContrast',\n",
    "    'Rotate',\n",
    "    'Posterize',\n",
    "    'Solarize',\n",
    "    'SolarizeAdd',\n",
    "    'Contrast',\n",
    "    'Brightness',\n",
    "    'Sharpness',\n",
    "    'ShearX',\n",
    "    #'ShearY',\n",
    "    'TranslateXRel',\n",
    "    #'TranslateYRel',\n",
    "    #'Gamma',\n",
    "    #'GridDistortion'\n",
    "    #'Cutout'  # NOTE I've implement this as random erasing separately\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8c637-cf0c-4ef4-a0bb-7776c5e6501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_RAND_TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a0a4e-58ae-4746-b4ad-d435bcd411c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = CC359_Dataset(CFG,df=cc359_df,root_dir=CFG.dataset_path,\n",
    "                                  voxel_spacing=CFG.voxel_spacing,transforms=None,#get_transforms(\"default\"),\n",
    "                                  mode=\"test\", cache=False,)\n",
    "\n",
    "for x, y, id in [train_dataset[0]]:\n",
    "    sdices = [np.round(sdices[id],3) for sdices in all_sdices if id in sdices.keys()] \n",
    "    x_slice = Image.fromarray(np.array(x.squeeze()[130])*255.).convert('L')\n",
    "    y_slice = Image.fromarray(np.array(y.squeeze()[130])*255.).convert('L')\n",
    "    \"\"\"fig, axes = plt.subplots(1,3, figsize=(30,10))\n",
    "    axes[0].set_title(f\"{x.shape}, {id} {id_to_scanner(id)}: {sdices}\")\n",
    "    inp = axes[0].imshow(x_slice)\n",
    "    plt.colorbar(inp,ax=axes[0])\n",
    "    \n",
    "    \n",
    "    aug_slice = ImageEnhance.Brightness(x_slice).enhance(1.7)\n",
    "    inp2 = axes[1].imshow(aug_slice)\n",
    "    plt.colorbar(inp2,ax=axes[1])\n",
    "    \n",
    "    inten = A.Posterize(p=1.,num_bits=3)\n",
    "    aug_slice = inten(image=np.array(x_slice))['image']\n",
    "    inp3 = axes[2].imshow(aug_slice)\n",
    "    plt.colorbar(inp3,ax=axes[2])\n",
    "    plt.show()\"\"\"\n",
    "    \n",
    "    fig, axs = plt.subplots(2,5, figsize=(15, 6))\n",
    "    fig.subplots_adjust(hspace =0.15, wspace=.001)\n",
    "    axs = axs.ravel()\n",
    "    aa_params = dict(\n",
    "            translate_const=int(256 * 0.020),\n",
    "            img_mean=tuple([0]),\n",
    "            #interpolation=str_to_pil_interp(interpolation)\n",
    "            )\n",
    "    for i, name in enumerate(_RAND_TRANSFORMS):\n",
    "        op = NAME_TO_OP[name]\n",
    "        args = LEVEL_TO_ARG[name] \n",
    "        factor = args(9,aa_params) if args is not None else tuple()\n",
    "        aug_slice, y_slice = op(x_slice,y_slice, *factor)\n",
    "        axs[i].set_title(name)\n",
    "        axs[i].imshow(aug_slice, \"gray\")\n",
    "        axs[i].axis('off')\n",
    "    plt.savefig('aug_viz.png', dpi=300)    \n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecb2a2-2d6a-4d0b-8f96-e3678595a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_tv_chambolle\n",
    "tv_denoised = denoise_tv_chambolle(np.array(x_slice), weight=0.05)\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.imshow(tv_denoised)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f78bd69-3469-45aa-bfad-55ece38fa2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intensity_normalization.normalize.fcm import FCMNormalize\n",
    "\n",
    "fcm_norm = FCMNormalize(tissue_type=\"wm\")\n",
    "\n",
    "from monai import transforms as T\n",
    "\n",
    "monai_T = T.Compose([T.CenterSpatialCropd(keys=(\"image\"),roi_size=[256,256,256]),\n",
    "                            T.SpatialPadd(keys=(\"image\"),spatial_size=[256,256,256])])\n",
    "\n",
    "x = nib.load(\"/home/mlk/cc359/images_scaled_voxel_spacing/CC0017_philips_15_50_F.nii.gz\")\n",
    "\n",
    "tfmed = monai_T({'image':x.get_fdata()[None,:,:,:]})       \n",
    "x_tfms = tfmed['image'].squeeze()\n",
    "normalized = fcm_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335cd6f8-98e2-42a3-a14b-9d4e3063b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nib.load(\"/home/mlk/cc359/images_scaled_voxel_spacing/CC0001_philips_15_55_M.nii.gz\")\n",
    "x2 = nib.load(\"/home/mlk/cc359/images_scaled_voxel_spacing/CC0261_ge_15_59_F.nii.gz\")\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(40,10))\n",
    "axes[0].imshow(x.get_fdata().transpose(2,0,1)[130])\n",
    "\n",
    "sns.distplot(x.get_fdata().reshape(-1), ax=axes[1])\n",
    "#axes[1].set_xlim(0,1)\n",
    "\n",
    "axes[2].imshow(x2.get_fdata().transpose(2,0,1)[130])\n",
    "\n",
    "sns.distplot(x2.get_fdata().reshape(-1), ax=axes[3])\n",
    "#axes[3].set_xlim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdee012-2ac7-477e-8580-b5b8231b051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "x_1 = scale_mri(x.get_fdata().reshape(-1),q_min=0,q_max=100)\n",
    "#x_1 = x_1[x_1>0.1]\n",
    "x_2 = scale_mri(x2.get_fdata().reshape(-1),q_min=0,q_max=100)\n",
    "#x_2 = x_2[x_2>0.1]\n",
    "sns.kdeplot(data=[x_1,x_2], fill=True, palette=\"crest\",\n",
    "   alpha=.5, linewidth=0,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8b766-f443-4ac5-94f3-c27c7828e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(30,10))\n",
    "axes[0].set_title(f\"{x.shape}, {id} {id_to_scanner(id)}: {sdices}\")\n",
    "axes[0].imshow(x_tfms.transpose(2,0,1)[130])\n",
    "\n",
    "sns.distplot(x.get_fdata().reshape(-1), ax=axes[1])\n",
    "#axes[1].set_xlim(0,1)\n",
    "\n",
    "sns.distplot(normalized.get_fdata().reshape(-1), ax=axes[2])\n",
    "axes[2].set_xlim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814ca23-aa58-453a-ac91-8e2055da20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y, id in train_dataset:\n",
    "    sdices = [np.round(sdices[id],3) for sdices in all_sdices if id in sdices.keys()] \n",
    "    \n",
    "    fig, axes = plt.subplots(1,3, figsize=(30,10))\n",
    "    axes[0].set_title(f\"{x.shape}, {id} {id_to_scanner(id)}: {sdices}\")\n",
    "    axes[0].imshow(x.squeeze()[130])\n",
    "    \n",
    "    sns.distplot(x[y==1.], ax=axes[1])\n",
    "    axes[1].set_xlim(0,1)\n",
    "    \n",
    "    sns.distplot(normalized[y==1.], ax=axes[2])\n",
    "    axes[2].set_xlim(0,1)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca9059-7b29-4dc8-bbd3-ea4633f9bb66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calc dataset mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb401d34-204f-446a-87f0-b8b44739fb28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0.\n",
    "for data, y, id in train_dataset:\n",
    "    data = data.unsqueeze(0)\n",
    "    batch_samples = data.size(0)\n",
    "    data = data.view(batch_samples, data.size(1), -1)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "    nb_samples += batch_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af0cccc-3a05-4357-a196-e8387b75f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean /= nb_samples\n",
    "std /= nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db0112d-5395-475c-9d5a-2d895c080563",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb10c47-82ea-49a5-8981-dfa737a38db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57194202-469c-4cf5-9db9-0e5ac80db9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "state_dict = torch.load(\"baseline_results/baseline_focal_lovasz_adam_default/mode_4/e_39.pth\",map_location=\"cpu\")['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588a7d1-de76-4fd7-b5eb-45a2e299694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_weights = []\n",
    "for k in state_dict.keys():\n",
    "    if \"conv\" in k and \"layer\" in k and \"weight\" in k:\n",
    "        conv_weights.append(np.array(state_dict[k]).reshape(-1))\n",
    "sns.displot(conv_weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1809e-be3e-43b1-99ed-331d1003418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "for x,y in test_dataset:\n",
    "    b,c,h,w = x.shape\n",
    "    \n",
    "    x_aug = denoise_tv_chambolle(np.array(x), weight=0.1)\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(x.squeeze(), \"gray\")\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(x_aug.squeeze(), \"gray\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84346f50-0da5-479e-8e2b-193e6158439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_by_random_id(dataset.load_image, dataset.load_segm, ids=df['id'],\n",
    "                      weights=ids_sampling_weights, random_state=seed),\n",
    "x,y = next(x[0])\n",
    "x = x[75]\n",
    "y = y[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e77f4-80f1-4483-b780-2e16e5fa6d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_aug = denoise_tv_chambolle(np.array(x), weight=0.1)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(x, \"gray\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(x_aug, \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150387a-29f6-452b-b9ce-83d666d54e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y==1)/np.sum(y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f664e-8d62-4fb3-8ed3-9c0ef75dee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Original\")\n",
    "plt.imshow(x, \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9d79a-a085-4b0e-818b-80f512e52cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "x = Image.fromarray(np.array(x)*255).convert('L')\n",
    "y = Image.fromarray(np.array(y)*255).convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d3c29c-244a-4c4f-a328-357d8f8fe0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rand_augment import *\n",
    "_LEVEL_DENOM = 10.\n",
    "_RAND_TRANSFORMS = [\n",
    "    'AutoContrast',\n",
    "    'Equalize',\n",
    "    'Invert',\n",
    "    'Rotate',\n",
    "    'Posterize',\n",
    "    'Solarize',\n",
    "    'SolarizeAdd',\n",
    "    'Color',\n",
    "    'Contrast',\n",
    "    'Brightness',\n",
    "    'Sharpness',\n",
    "    'ShearX',\n",
    "    'ShearY',\n",
    "    'TranslateXRel',\n",
    "    'TranslateYRel',\n",
    "    #'Cutout'  # NOTE I've implement this as random erasing separately\n",
    "]\n",
    "\n",
    "_FILL = (128, 128, 128)\n",
    "\n",
    "_HPARAMS_DEFAULT = dict(\n",
    "    translate_const=250,\n",
    "    img_mean=_FILL,\n",
    ")\n",
    "mean = [0.5]\n",
    "\n",
    "hparams = dict(\n",
    "            translate_const=int(256 * 0.45),\n",
    "            img_mean=tuple([min(255, round(255 * x)) for x in mean]),\n",
    "            )\n",
    "\n",
    "config_str = \"rand-m9-mstd0.5\"\n",
    "\n",
    "magnitude = _LEVEL_DENOM  # default to _LEVEL_DENOM for magnitude (currently 10)\n",
    "num_layers = 2  # default to 2 ops per image\n",
    "weight_idx = None  # default to no probability weights for op choice\n",
    "transforms = _RAND_TRANSFORMS\n",
    "config = config_str.split('-')\n",
    "assert config[0] == 'rand'\n",
    "config = config[1:]\n",
    "for c in config:\n",
    "    cs = re.split(r'(\\d.*)', c)\n",
    "    if len(cs) < 2:\n",
    "        continue\n",
    "    key, val = cs[:2]\n",
    "    if key == 'mstd':\n",
    "        # noise param / randomization of magnitude values\n",
    "        mstd = float(val)\n",
    "        if mstd > 100:\n",
    "            # use uniform sampling in 0 to magnitude if mstd is > 100\n",
    "            mstd = float('inf')\n",
    "        hparams.setdefault('magnitude_std', mstd)\n",
    "    elif key == 'mmax':\n",
    "        # clip magnitude between [0, mmax] instead of default [0, _LEVEL_DENOM]\n",
    "        hparams.setdefault('magnitude_max', int(val))\n",
    "    elif key == 'inc':\n",
    "        if bool(val):\n",
    "            transforms = _RAND_INCREASING_TRANSFORMS\n",
    "    elif key == 'm':\n",
    "        magnitude = int(val)\n",
    "    elif key == 'n':\n",
    "        num_layers = int(val)\n",
    "    elif key == 'w':\n",
    "        weight_idx = int(val)\n",
    "    else:\n",
    "        assert False, 'Unknown RandAugment config section'\n",
    "ra_ops = rand_augment_ops(magnitude=magnitude, hparams=hparams, transforms=transforms)\n",
    "choice_weights = None if weight_idx is None else _select_rand_weights(weight_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae752c3-a4b0-4cf0-89e1-ac55abab7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_TO_OP.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618e596-1e87-4092-afc6-970314cad85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e08d62-025b-4a66-894f-ba47200f628d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rand_augment import *\n",
    "\n",
    "\n",
    "for name,augment_fkt in zip(NAME_TO_OP.keys(),ra_ops):\n",
    "    \n",
    "    x_aug,y_aug = augment_fkt(x, y)\n",
    "    plt.title(augment_fkt.name)\n",
    "    plt.imshow(x_aug, \"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ca481-73b3-4a3b-ae2d-e450c4f1e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rrc import *\n",
    "\n",
    "scale = tuple((0.08, 1.0))  # default imagenet scale range\n",
    "ratio = tuple((3./4., 4./3.)) # default imagenet ratio range\n",
    "mean = [0.5]\n",
    "_pil_interpolation_to_str = {\n",
    "    Image.NEAREST: 'nearest',\n",
    "    Image.BILINEAR: 'bilinear',\n",
    "    Image.BICUBIC: 'bicubic',\n",
    "    Image.BOX: 'box',\n",
    "    Image.HAMMING: 'hamming',\n",
    "    Image.LANCZOS: 'lanczos',\n",
    "}\n",
    "_str_to_pil_interpolation = {b: a for a, b in _pil_interpolation_to_str.items()}\n",
    "\n",
    "\n",
    "def str_to_pil_interp(mode_str):\n",
    "    return _str_to_pil_interpolation[mode_str]\n",
    "\n",
    "auto_augment = \"rand-m9-mstd0.5\"\n",
    "interpolation = 'random'\n",
    "rrc = RandomResizedCropAndInterpolation((256,256), scale=scale, ratio=ratio, interpolation=interpolation)\n",
    "\n",
    "plt.title(\"RandomResizeCrop\")\n",
    "plt.imshow(rrc(x,y)[0], \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1702b60-9467-440b-bfac-e9a1c9667258",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,idx in test_dataset:\n",
    "    print(idx,x.shape,x.min(),x.max())\n",
    "    c,h,w = x.shape\n",
    "    out = np.zeros((1,h,w*2))\n",
    "    out[:,:,:w] = x[c//2]\n",
    "    out[:,:,w:] = y[c//2]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(out.squeeze())\n",
    "    plt.show()\n",
    "    \n",
    "    x1 = preprocessed_dataset.load_image(idx)\n",
    "    y1 = preprocessed_dataset.load_segm(idx)\n",
    "\n",
    "    print(idx,x1.shape,x1.min(),x1.max())\n",
    "    c,h,w = x.shape\n",
    "    out = np.zeros((1,h,w*2))\n",
    "    out[:,:,:w] = x1[c//2]\n",
    "    # out[:,:,w:] = y1[c//2]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(out.squeeze())\n",
    "    plt.show()\n",
    "    \n",
    "    x_diff = x-x1\n",
    "    print(x_diff.min(),x_diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e01d6-ac28-4ec8-86e4-a9b297f1f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpipe.io import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ea221-d933-49fd-a90d-863a18bf2b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3549f4d-e7fc-4ca5-9200-f11e90099816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from intensity_normalization.normalize.fcm import FCMNormalize\n",
    "\n",
    "fcm_norm = FCMNormalize(tissue_type=\"wm\")\n",
    "\n",
    "\n",
    "\n",
    "voxel_spacing=CFG.voxel_spacing\n",
    "def scale_voxel_spacing(idx, img, segm, sample_voxel_spacing):\n",
    "    sample_vxsp = sample_voxel_spacing\n",
    "    scale_factor = np.array(sample_vxsp) / np.array(voxel_spacing)\n",
    "    scale_factor = np.nan_to_num(scale_factor, nan=1)\n",
    "    img = zoom(img, scale_factor, order=3)\n",
    "    segm = zoom(segm, scale_factor, order=3)\n",
    "    return img,segm\n",
    "\n",
    "img_fns, mask_fns = [],[]\n",
    "for i,idx in enumerate(cc359_df['id']):\n",
    "    img_fn = cc359_df['MRI'][i]\n",
    "    seg_fn = cc359_df['brain_mask'][i]\n",
    "    sample_voxel_spacing = [cc359_df['x'][i], cc359_df['y'][i], cc359_df['z'][i]]\n",
    "    \n",
    "    img_file = nib.load(f\"{CFG.dataset_path}/{img_fn}\")\n",
    "    image = img_file.get_fdata()\n",
    "    seg_file = nib.load(f\"{CFG.dataset_path}/{seg_fn}\")\n",
    "    seg = seg_file.get_fdata() \n",
    "    \n",
    "    image, seg = scale_voxel_spacing(idx,image,seg,sample_voxel_spacing)\n",
    "    img_file.data = image\n",
    "    #seg_file.data = seg\n",
    "    normalized = fcm_norm(img_file)\n",
    "    print(img_fn,image.min())\n",
    "    img_out = f\"{CFG.dataset_path}/{img_fn.replace('images','images_svs_norm')}\"\n",
    "    #msk_out = f\"{CFG.dataset_path}/{seg_fn.replace('masks','masks_svs_norm')}\"\n",
    "    nib.save(normalized,img_out)\n",
    "    #nib.save(seg_file,msk_out)\n",
    "    img_fns.append(img_fn.replace('images','images_svs_norm'))\n",
    "    #mask_fns.append(seg_fn.replace('masks','masks_svs_norm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7becd6df-7687-4cea-8143-d76255564150",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc359_df['MRI_scaled_voxel_spacing'] = img_fns\n",
    "cc359_df['brain_mask_scaled_voxel_spacing'] = mask_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa64e46-84c6-4c81-b004-41e9b75c177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc359_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03206202-9b76-4f58-8461-07a29631de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc359_df.to_csv(f\"{CFG.dataset_path}/meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b53ce06-95aa-4214-8174-cd802ac7b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spottunet.dataset.cc359 import *\n",
    "from spottunet.split import one2all\n",
    "from spottunet.torch.module.unet import UNet2D\n",
    "from spottunet.utils import sdice\n",
    "from dpipe.im.metrics import dice_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler \n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from monai import transforms as T\n",
    "from monai.transforms import Compose, apply_transform\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "import json\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from dpipe.im.shape_ops import zoom\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset.dataloader import *\n",
    "from dataset.loader import *\n",
    "# \n",
    "cc359_df = pd.read_csv(f\"{CFG.dataset_path}/meta.csv\",delimiter=\",\")\n",
    "seed = 0xBadCafe\n",
    "val_size = 4\n",
    "n_experiments = len(cc359_df.fold.unique())\n",
    "split = one2all(df=cc359_df,val_size=val_size)[:n_experiments]\n",
    "train_df = cc359_df.iloc[split[0][0]].reset_index()\n",
    "\n",
    "\"\"\"train_dataset = CC359_Dataset(df=train_df,root_dir=CFG.dataset_path,\n",
    "                              voxel_spacing=CFG.voxel_spacing,transforms=tfms,\n",
    "                              mode=\"train\", cache=True)\"\"\"\n",
    "\n",
    "valid_df = cc359_df.iloc[split[0][1]].reset_index()\n",
    "\n",
    "valid = CC359_Dataset(df=valid_df,root_dir=CFG.dataset_path,\n",
    "                              voxel_spacing=CFG.voxel_spacing,transforms=None,\n",
    "                              mode=\"val\", cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed29036d-4780-45f8-9511-1426b2bba640",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,_id = next(iter(valid))\n",
    "plt.imshow(x[180].squeeze(), \"gray\")\n",
    "plt.show()\n",
    "plt.imshow(y[180])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649d3b9-a1ae-4c18-a051-84a8257d06a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualize Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bdbb35-808c-4fe5-8595-775b32b21e38",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"meta++.csv\",delimiter=\",\")\n",
    "data_path=\"/media/mlk/New Volume/conp-dataset/projects/calgary-campinas/CC359\"\n",
    "\n",
    "df[\"max_intensity\"] = np.zeros(len(df))\n",
    "df[\"size_s\"] = np.zeros(len(df))\n",
    "df[\"size_l\"] = np.zeros(len(df))\n",
    "\n",
    "for fn in os.listdir(os.path.join(data_path,\"images\")):\n",
    "    df_fn = os.path.join(\"images\",fn)\n",
    "    fn_p = os.path.join(data_path,\"images\",fn)\n",
    "    raw_img_data = nib.load(fn_p).get_fdata()\n",
    "    np.unique(raw_img_data)\n",
    "    df.loc[df[\"MRI\"]==df_fn,\"max_intensity\"] = raw_img_data.max()\n",
    "    min_s, max_s = np.unique(raw_img_data.shape)\n",
    "    df.loc[df[\"MRI\"]==df_fn,\"size_s\"] = min_s\n",
    "    df.loc[df[\"MRI\"]==df_fn,\"size_l\"] = max_s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94cccf-7b6b-4bb7-baa1-a7f4f317ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for td in tds:\n",
    "    df[td] = np.zeros(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7670d8-09c0-461b-9a9d-883bc6fc0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dpipe.io import load\n",
    "path_base = Path('baseline_results/baseline_lovasz_default')\n",
    "\n",
    "meta = pd.read_csv(f\"meta.csv\",delimiter=\",\", index_col='id')\n",
    "meta.head()\n",
    "\n",
    "all_sdices = {}\n",
    "for s in sorted(meta['fold'].unique()):\n",
    "    sdices = load(path_base / f'mode_{s}/sdice_score.json')\n",
    "    all_sdices[s] = sdices\n",
    "\n",
    "tds = [\"siemens15\",\"siemens3\",\"ge15\",\"ge3\",\"philip15\",\"philips3\"]\n",
    "for fold in all_sdices.keys():\n",
    "    sdices = all_sdices[fold]\n",
    "    for id in sdices.keys():\n",
    "        dice = sdices[id]\n",
    "        df.loc[df[\"id\"]==id, tds[fold]] = np.round(dice,4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9518dd7e-263e-4daa-8e2d-81b0a29a3b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a65e5a-f262-497a-b2fc-f756d9f942aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "coefs = []\n",
    "for td in tds:\n",
    "    df_subset = df.drop(index=df[df[td]==0.0].index)\n",
    "    X = df_subset.drop(columns=[\"id\",\"tomograph_model\",\"tesla_value\"])\n",
    "    X = X.drop(columns=tds)\n",
    "    y = df_subset[td]\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    print(reg.score(X,y))\n",
    "    print(reg.coef_, reg.intercept_)\n",
    "    coefs.append(reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6672d-8402-4e0b-bc3b-63a297cf8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=coefs, index=tds, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abfb8e1-424d-424f-a4db-8c63f7974810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dee8ab-cdf2-4671-ad52-af24a368d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0111661-a46b-49b0-a739-5798e4264c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.boxplot(data=df, x=\"fold\", y=\"size_0\")\n",
    "plt.show()\n",
    "g = sns.boxplot(data=df, x=\"fold\", y=\"size_1\")\n",
    "plt.show()\n",
    "g = sns.boxplot(data=df, x=\"fold\", y=\"size_2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f6dde-f361-4de6-9ea2-2c76c5e10429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "g = sns.boxplot(data=df, y=\"max_intensity\", x=\"fold\", )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa4e355-bb09-4326-ab3c-b2bea50892bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for fn in df.loc[df['fold']==5,\"MRI\"]:\n",
    "    print(fn,raw_img_data.max())\n",
    "    df_fn = os.path.join(fn)\n",
    "    fn_p = os.path.join(data_path,fn)\n",
    "    raw_img_data = nib.load(fn_p).get_fdata()\n",
    "    plt.imshow(raw_img_data[75])\n",
    "    plt.show()\n",
    "    sns.displot(raw_img_data.reshape(-1)[raw_img_data.reshape(-1)!=0.0], log_scale=(False,True))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c7645b-54fb-49bb-be9e-7cc9816c1272",
   "metadata": {},
   "outputs": [],
   "source": [
    "CC0027_philips_15_41_M.nii.gz\n",
    "CC0255_ge_15_57_F.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a9f22-6972-4037-a60c-3d94220583c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = nib.load(os.path.join(data_path,f\"images/CC0027_philips_15_41_M.nii.gz\")).get_fdata().transpose(2,0,1)\n",
    "\n",
    "x2 = nib.load(os.path.join(data_path,f\"images/CC0255_ge_15_57_F.nii.gz\")).get_fdata().transpose(2,0,1)\n",
    "\n",
    "print(x1.shape,x1.dtype,x1.min(),x1.max(),)\n",
    "print(x2.shape,x2.dtype,x2.min(),x2.max())\n",
    "plt.imshow(x1[130])\n",
    "plt.show()\n",
    "plt.imshow(x2[130])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44e287-c481-418d-be47-4eeb6ea423fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_mri(image, q_min=1, q_max=99):\n",
    "        #image = np.clip(np.float32(image), *np.percentile(np.float32(image), [q_min, q_max]))\n",
    "        image -= np.min(image)\n",
    "        image /= np.max(image)\n",
    "        return np.float32(image)\n",
    "\n",
    "from monai import transforms as T\n",
    "monai_T = T.Compose([T.CenterSpatialCropd(keys=(\"image\",\"seg\"),roi_size=[256,256,256]),\n",
    "                         T.SpatialPadd(keys=(\"image\",\"seg\"),spatial_size=[256,256,256])])\n",
    "\n",
    "fn = \"CC0255_ge_15_57_F.nii.gz\"\n",
    "fn2 = \"CC0255_ge_15_57_F_ss.nii.gz\"\n",
    "raw_img_data = nib.load(os.path.join(data_path,f\"images/{fn}\")).get_fdata().transpose(2,0,1)\n",
    "raw_seg_data = nib.load(os.path.join(data_path,f\"masks/{fn2}\")).get_fdata().transpose(2,0,1)\n",
    "raw_img_data = scale_mri(raw_img_data)\n",
    "tfmed = monai_T({'image':raw_img_data[None,:,:,:],\n",
    "                 'seg':raw_seg_data[None,:,:,:]})       \n",
    "raw_img_data = tfmed['image'].squeeze()\n",
    "raw_seg_data = tfmed['seg'].squeeze()\n",
    "\n",
    "#x1 = scale_mri(x1)\n",
    "tfmed = monai_T({'image':x1[None,:,:,:],\n",
    "                 'seg':x1[None,:,:,:]})       \n",
    "x1 = tfmed['image'].squeeze()\n",
    "\n",
    "preds = np.load(os.path.join(\"predictions/baseline23_2class_lovasz_default/mode_3\",f\"{fn.split('_')[0]}.npy\"))\n",
    "\n",
    "combined = np.concatenate((raw_img_data,raw_seg_data*1,preds*1), axis=2)\n",
    "print(raw_img_data.max())\n",
    "create_animation(np.concatenate((raw_img_data,x1), axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45adf4ed-8496-456a-b2f3-025ce38b3a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(raw_img_data.shape,raw_img_data.min(),raw_img_data.max())\n",
    "fig, (ax,bx,cx) = plt.subplots(1,3, figsize=(10,20))\n",
    "ax.imshow(raw_img_data[2], \"gray\")\n",
    "bx.imshow(raw_seg_data[2], \"gray\")\n",
    "cx.imshow(preds[2], \"gray\")\n",
    "plt.show()\n",
    "\n",
    "fig, (ax,bx,cx) = plt.subplots(1,3, figsize=(10,20))\n",
    "ax.imshow(raw_img_data[70], \"gray\")\n",
    "bx.imshow(raw_seg_data[70], \"gray\")\n",
    "cx.imshow(preds[70], \"gray\")\n",
    "plt.show()\n",
    "fig, (ax,bx,cx) = plt.subplots(1,3, figsize=(10,20))\n",
    "ax.imshow(raw_img_data[130], \"gray\")\n",
    "bx.imshow(raw_seg_data[130], \"gray\")\n",
    "cx.imshow(preds[130]*255, \"gray\")\n",
    "plt.show()\n",
    "print(raw_img_data[199].max())\n",
    "fig, (ax,bx,cx) = plt.subplots(1,3, figsize=(10,20))\n",
    "ax.imshow(raw_img_data[199], \"gray\")\n",
    "bx.imshow(raw_seg_data[199], \"gray\")\n",
    "cx.imshow(preds[199], \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f72c7d-649a-4a85-b247-08d1cfcd6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64ed8e-7c63-4bd3-a5f1-bb119c3eb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "A.Posterize(num_bits=(0,4))\n",
    "fig, (ax,bx,cx) = plt.subplots(1,3, figsize=(10,20))\n",
    "ax.imshow(tmf(image=raw_img_data[199])['image'], \"gray\")\n",
    "bx.imshow(tmf(image=raw_seg_data[199])['image'], \"gray\")\n",
    "cx.imshow(tfm2(image=raw_img_data[199])['image'], \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98f74d-3b14-4a04-b567-feae1e66a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x1.reshape(-1)[x1.reshape(-1)!=0.0], log_scale=(False,True))\n",
    "plt.show()\n",
    "sns.displot(x2.reshape(-1)[x2.reshape(-1)!=0.0], log_scale=(False,True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e74e4-64f1-45d4-8a1a-fa0cf1d93077",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.displot(scale_mri(x1).reshape(-1)[x1.reshape(-1)!=0], log_scale=(False,True))\n",
    "plt.show()\n",
    "sns.displot(scale_mri(x2).reshape(-1)[x2.reshape(-1)!=0], log_scale=(False,True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b765c13-be80-402d-b117-589a41a2f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.zeros((256,256))\n",
    "noise[:,30:50] = np.arange(0,20)[::-1]\n",
    "plt.imshow(noise)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc913c0-02ab-4ec5-8bcf-587955706cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ceb87-1269-4125-8855-82b7f8773bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "vol = io.imread(\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/attention-mri.tif\")\n",
    "volume = vol.T\n",
    "r, c = volume[0].shape\n",
    "\n",
    "# Define frames\n",
    "import plotly.graph_objects as go\n",
    "nb_frames = 68\n",
    "\n",
    "fig = go.Figure(frames=[go.Frame(data=go.Surface(\n",
    "    z=(6.7 - k * 0.1) * np.ones((r, c)),\n",
    "    surfacecolor=np.flipud(volume[67 - k]),\n",
    "    cmin=0, cmax=200\n",
    "    ),\n",
    "    name=str(k) # you need to name the frame for the animation to behave properly\n",
    "    )\n",
    "    for k in range(nb_frames)])\n",
    "\n",
    "# Add data to be displayed before animation starts\n",
    "fig.add_trace(go.Surface(\n",
    "    z=6.7 * np.ones((r, c)),\n",
    "    surfacecolor=np.flipud(volume[67]),\n",
    "    colorscale='Gray',\n",
    "    cmin=0, cmax=200,\n",
    "    colorbar=dict(thickness=20, ticklen=4)\n",
    "    ))\n",
    "\n",
    "\n",
    "def frame_args(duration):\n",
    "    return {\n",
    "            \"frame\": {\"duration\": duration},\n",
    "            \"mode\": \"immediate\",\n",
    "            \"fromcurrent\": True,\n",
    "            \"transition\": {\"duration\": duration, \"easing\": \"linear\"},\n",
    "        }\n",
    "\n",
    "sliders = [\n",
    "            {\n",
    "                \"pad\": {\"b\": 10, \"t\": 60},\n",
    "                \"len\": 0.9,\n",
    "                \"x\": 0.1,\n",
    "                \"y\": 0,\n",
    "                \"steps\": [\n",
    "                    {\n",
    "                        \"args\": [[f.name], frame_args(0)],\n",
    "                        \"label\": str(k),\n",
    "                        \"method\": \"animate\",\n",
    "                    }\n",
    "                    for k, f in enumerate(fig.frames)\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "         title='Slices in volumetric data',\n",
    "         width=600,\n",
    "         height=600,\n",
    "         scene=dict(\n",
    "                    zaxis=dict(range=[-0.1, 6.8], autorange=False),\n",
    "                    aspectratio=dict(x=1, y=1, z=1),\n",
    "                    ),\n",
    "         updatemenus = [\n",
    "            {\n",
    "                \"buttons\": [\n",
    "                    {\n",
    "                        \"args\": [None, frame_args(50)],\n",
    "                        \"label\": \"&#9654;\", # play symbol\n",
    "                        \"method\": \"animate\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"args\": [[None], frame_args(0)],\n",
    "                        \"label\": \"&#9724;\", # pause symbol\n",
    "                        \"method\": \"animate\",\n",
    "                    },\n",
    "                ],\n",
    "                \"direction\": \"left\",\n",
    "                \"pad\": {\"r\": 10, \"t\": 70},\n",
    "                \"type\": \"buttons\",\n",
    "                \"x\": 0.1,\n",
    "                \"y\": 0,\n",
    "            }\n",
    "         ],\n",
    "         sliders=sliders\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch1.9] *",
   "language": "python",
   "name": "conda-env-torch1.9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
