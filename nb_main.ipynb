{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2eda7f7-d32b-4573-90a0-5ca29fcc0738",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TODOs\n",
    "\n",
    "- [x] Inference Loop\n",
    "- [ ] Oracle?\n",
    "- [ ] Finetune\n",
    "- [ ] Spottune\n",
    "- [x] Voxelization NaN to num\n",
    "- [x] Precompute 3rd order sample voxel spacing upfront\n",
    "\n",
    "\n",
    "#### Augs?\n",
    "- [ ] LAMB\n",
    "- [ ] Label Smoothing\n",
    "- [ ] Stoch. depth\n",
    "- [ ] CutMix / MixUp\n",
    "- [ ] Hflip? (prob not)\n",
    "- [ ] RandomResizedCrop\n",
    "- [ ] Rand Augment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47db57e0-abf3-47c6-83cf-603c084f05df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spottunet.dataset.cc359 import *\n",
    "from spottunet.split import one2all\n",
    "from spottunet.torch.module.unet import UNet2D\n",
    "from spottunet.utils import sdice\n",
    "from dpipe.im.metrics import dice_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler \n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from monai import transforms as T\n",
    "from monai.transforms import Compose, apply_transform\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "import json\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from dpipe.im.shape_ops import zoom\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f11427e-96f7-417b-847d-26360ba56f54",
   "metadata": {},
   "source": [
    "### Config & Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5145f862-280b-4ff1-b07a-cca51299f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from config import CFG\n",
    "from utils import *\n",
    "\n",
    "def class2dict(f):\n",
    "    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90703324-98f7-48e1-a6d7-d73113efb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataloader import *\n",
    "from dataset.loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40bf27fc-a709-45df-a5f9-8da595925215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cc359_df = pd.read_csv(f\"{CFG.dataset_path}/meta.csv\",delimiter=\",\")\\nseed = 0xBadCafe\\nval_size = 4\\nn_experiments = len(cc359_df.fold.unique())\\nsplit = one2all(df=cc359_df,val_size=val_size)[:n_experiments]\\ntrain_df = cc359_df.iloc[split[0][0]].reset_index()\\n\\ntrain_dataset = CC359_Dataset(df=train_df,root_dir=CFG.dataset_path,\\n                              voxel_spacing=CFG.voxel_spacing,transforms=tfms,\\n                              mode=\"train\")'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"cc359_df = pd.read_csv(f\"{CFG.dataset_path}/meta.csv\",delimiter=\",\")\n",
    "seed = 0xBadCafe\n",
    "val_size = 4\n",
    "n_experiments = len(cc359_df.fold.unique())\n",
    "split = one2all(df=cc359_df,val_size=val_size)[:n_experiments]\n",
    "train_df = cc359_df.iloc[split[0][0]].reset_index()\n",
    "\n",
    "train_dataset = CC359_Dataset(df=train_df,root_dir=CFG.dataset_path,\n",
    "                              voxel_spacing=CFG.voxel_spacing,transforms=tfms,\n",
    "                              mode=\"train\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93800101-8c21-471e-a888-5e45cb8f0065",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d653cd4-6105-43af-9eb3-f66721d30c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6276a6a-70c1-4f4d-80e2-3bffbb951a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader import *\n",
    "def run_fold(fold):\n",
    "    result_dir = CFG.results_dir + \"/mode_\"+str(fold)\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "    #wandb.tensorboard.patch(root_logdir=result_dir+\"/logs\")\n",
    "    run = wandb.init(project=\"domain_shift\",\n",
    "                     group=CFG.model_name,\n",
    "                     name=f\"mode_{str(fold)}\",\n",
    "                     job_type=\"rand_slice3\",\n",
    "                     config=class2dict(CFG),\n",
    "                     reinit=True,\n",
    "                     sync_tensorboard=True)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir=result_dir+\"/logs\")\n",
    "    cc359_df = pd.read_csv(f\"{CFG.dataset_path}/meta.csv\",delimiter=\",\")\n",
    "    \n",
    "\n",
    "    #model = smp.Unet(encoder_name=\"resnet50\", encoder_weights=\"swsl\", in_channels=CFG.n_chans_in,classes=CFG.n_chans_out)\n",
    "\n",
    "    model = UNet2D(n_chans_in=CFG.n_chans_in, n_chans_out=CFG.n_chans_out, n_filters_init=CFG.n_filters)\n",
    "    model.to(CFG.device)\n",
    "    optimizer = CFG.optim(model.parameters(),lr=CFG.lr,weight_decay=CFG.wd)\n",
    "    #optimizer = CFG.optim(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd, betas=(.9, .999), adam=False)\n",
    "    scheduler = CFG.scheduler(optimizer, lr_lambda=lambda epoch: CFG.scheduler_multi_lr_fact )\n",
    "    criterion = CFG.crit\n",
    "    \n",
    "\n",
    "\n",
    "    seed = 0xBadCafe\n",
    "    val_size = 4\n",
    "    n_experiments = len(cc359_df.fold.unique())\n",
    "    split = one2all(df=cc359_df,val_size=val_size)[:n_experiments]\n",
    "\n",
    "\n",
    "    train_df = cc359_df.iloc[split[fold][0]].reset_index()\n",
    "    valid_df = cc359_df.iloc[split[fold][1]].reset_index()\n",
    "    test_df  = cc359_df.iloc[split[fold][2]].reset_index()\n",
    "\n",
    "    print(\"Caching Train Data ...\")\n",
    "    train_dataset = CC359_Dataset(df=train_df,root_dir=CFG.dataset_path,\n",
    "                                  voxel_spacing=CFG.voxel_spacing,transforms=tfms,\n",
    "                                  mode=\"train\")\n",
    "    print(\"Caching Valid Data ...\")\n",
    "    valid_dataset = CC359_Dataset(df=valid_df,root_dir=CFG.dataset_path,\n",
    "                                  voxel_spacing=CFG.voxel_spacing,transforms=None,\n",
    "                                  mode=\"val\")\n",
    "    test_dataset = CC359_Dataset(df=test_df,root_dir=CFG.dataset_path,\n",
    "                                  voxel_spacing=CFG.voxel_spacing,transforms=None,\n",
    "                                  mode=\"test\", cache=False)\n",
    "\n",
    "    train_loader = PrefetchLoader(DataLoader(train_dataset,\n",
    "                                              batch_size=CFG.bs,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=CFG.num_workers,\n",
    "                                              sampler=None,\n",
    "                                              collate_fn=fast_collate,\n",
    "                                              pin_memory=False,\n",
    "                                              drop_last=True),\n",
    "                                    fp16=CFG.fp16)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.bs,shuffle=False,\n",
    "                              num_workers=CFG.num_workers,pin_memory = False)\n",
    "    test_dataloader = DataLoader(test_dataset, \n",
    "                                  batch_size=1,shuffle=False,\n",
    "                                  num_workers=1,pin_memory = False)\n",
    "\n",
    "    \"\"\"from torch_lr_finder import LRFinder\n",
    "    lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "    lr_finder.range_test(train_loader, end_lr=100, num_iter=100)\n",
    "    lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "    lr_finder.reset()\"\"\"\n",
    "    \n",
    "    trainer = Trainer(model, \n",
    "                      CFG.device, \n",
    "                      optimizer,\n",
    "                      scheduler,\n",
    "                      criterion,writer)\n",
    "    \n",
    "    history = trainer.fit(\n",
    "            CFG.epochs, \n",
    "            train_loader, \n",
    "            valid_loader, \n",
    "            f\"{CFG.exp_name}/mode_{str(fold)}/\", \n",
    "            CFG.epochs,\n",
    "        )\n",
    "    trainer.test(test_dataloader,result_dir)\n",
    "    td_sdice = get_target_domain_metrics(CFG.dataset_path,Path(CFG.results_dir),fold)\n",
    "    wandb.log(td_sdice)\n",
    "    writer.close()\n",
    "    run.finish()\n",
    "\n",
    "    del trainer\n",
    "    del train_loader\n",
    "    del valid_loader\n",
    "    del train_dataset\n",
    "    del valid_dataset\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aacc1c9e-939c-40d2-93e0-4e5d36197e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmklasen\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/mklasen/domain_shift/runs/1xa3lys4\" target=\"_blank\">mode_0</a></strong> to <a href=\"https://wandb.ai/mklasen/domain_shift\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching Train Data ...\n",
      "(12000, 256, 256)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='56' class='' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [56/56 00:48<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching Valid Data ...\n",
      "(1000, 256, 256)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4/4 00:03<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      5.00% [5/100 27:21<8:39:48]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>train/dice</th>\n",
       "      <th>train/sdice</th>\n",
       "      <th>valid/loss</th>\n",
       "      <th>valid/dice</th>\n",
       "      <th>valid/sdice</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.5618</td>\n",
       "      <td>0.6702</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.5610</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.4972</td>\n",
       "      <td>0.8335</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.4802</td>\n",
       "      <td>0.8477</td>\n",
       "      <td>0.8884</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>0.5252</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>0.5162</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.79% [3/168 00:05<04:53 train_loss: 0.4396, LR: 1.63e-04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improved from inf to 0.5610. Saved model to 'baseline5/mode_0/e0-loss0.561.pth'\n",
      "improved from 0.5610 to 0.5484. Saved model to 'baseline5/mode_0/e1-loss0.548.pth'\n",
      "improved from 0.5484 to 0.5252. Saved model to 'baseline5/mode_0/e3-loss0.525.pth'\n",
      "improved from 0.5252 to 0.5162. Saved model to 'baseline5/mode_0/e4-loss0.516.pth'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34900/1039165449.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_34900/3793241779.py\u001b[0m in \u001b[0;36mrun_fold\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     77\u001b[0m                       criterion,writer)\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     history = trainer.fit(\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_34900/1821424900.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, train_loader, valid_loader, save_path, patience)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sdice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_34900/1821424900.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, train_loader, mb, n_epoch)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0md_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0msd_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoxel_spacing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdice_tolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0msd_score\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NaN sd_score\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mall_dice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mall_sdice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mlk/New Volume/Lab/domain_shift_anatomy/spottunet/utils.py\u001b[0m in \u001b[0;36msdice\u001b[0;34m(a, b, spacing, tolerance)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msdice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0msurface_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurf_dc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_surface_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msurf_dc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_surface_dice_at_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurface_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mlk/New Volume/Lab/surface-distance/surface_distance/metrics.py\u001b[0m in \u001b[0;36mcompute_surface_distances\u001b[0;34m(mask_gt, mask_pred, spacing_mm)\u001b[0m\n\u001b[1;32m    276\u001b[0m   \u001b[0;31m# sort them by distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdistances_gt_to_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     distances_gt_to_pred, surfel_areas_gt = _sort_distances_surfels(\n\u001b[0m\u001b[1;32m    279\u001b[0m         distances_gt_to_pred, surfel_areas_gt)\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/mlk/New Volume/Lab/surface-distance/surface_distance/metrics.py\u001b[0m in \u001b[0;36m_sort_distances_surfels\u001b[0;34m(distances, surfel_areas)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msorted\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurfel_areas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \"\"\"\n\u001b[0;32m--> 132\u001b[0;31m   \u001b[0msorted_surfels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurfel_areas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted_surfels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_surfels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold in CFG.fold:\n",
    "    run_fold(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99168e92-5255-4b17-930a-cbac5ed9ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210cef89-6bad-4c60-9566-7ab41f71a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run(fold):\n",
    "    result_dir = CFG.results_dir + \"/mode_\"+str(fold)\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "    \n",
    "    cc359_df = pd.read_csv(f\"{CFG.dataset_path}/meta.csv\",delimiter=\",\")\n",
    "\n",
    "    #model = UNet2D(n_chans_in=CFG.n_chans_in, n_chans_out=CFG.n_chans_out, n_filters_init=CFG.n_filters)\n",
    "    model = smp.Unet(encoder_name=\"resnet50\", encoder_weights=\"swsl\", in_channels=CFG.n_chans_in,classes=CFG.n_chans_out)\n",
    "    model.load_state_dict(torch.load(f\"{result_dir}/mode_{fold}_best_model.pth\")[\"model_state_dict\"])\n",
    "    \n",
    "    model.to(CFG.device)\n",
    "\n",
    "\n",
    "    seed = 0xBadCafe\n",
    "    val_size = 4\n",
    "    n_experiments = len(cc359_df.fold.unique())\n",
    "    split = one2all(df=cc359_df,val_size=val_size)[:n_experiments]\n",
    "\n",
    "    test_df  = cc359_df.iloc[split[fold][2]].reset_index()\n",
    "\n",
    "    test_dataset = CC359_Dataset(df=test_df,root_dir=CFG.dataset_path,\n",
    "                                  voxel_spacing=CFG.voxel_spacing,transforms=tfms,\n",
    "                                  mode=\"test\", cache=False)\n",
    "    trainer = Trainer(model,CFG.device, None,None,None,None)\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset, \n",
    "                                  batch_size=1,shuffle=False,\n",
    "                                  num_workers=1,pin_memory = False)\n",
    "\n",
    "    trainer.test(test_dataloader, result_dir)\n",
    "    \n",
    "for fold in CFG.fold:\n",
    "    test_run(fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3aee5f-7253-47ec-8b54-690fee267fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dpipe.io import load\n",
    "\n",
    "path_base = 'baseline_2/'\n",
    "\n",
    "meta = pd.read_csv(f\"{CFG.dataset_path}/meta.csv\",delimiter=\",\", index_col='id')\n",
    "meta.head()\n",
    "\n",
    "records = []\n",
    "for s in sorted(meta['fold'].unique()):\n",
    "    res_row = {}\n",
    "    \n",
    "    # one2all results:\n",
    "    sdices = load(path_base / f'mode_{s}/sdice_score.json')\n",
    "    #sdices = dict(sorted(sdices.items()))\n",
    "    for t in sorted(set(meta['fold'].unique()) - {s}):\n",
    "        df_row = meta[meta['fold'] == t].iloc[0]\n",
    "        target_name = df_row['tomograph_model'] + str(df_row['tesla_value'])\n",
    "        \n",
    "        ids_t = meta[meta['fold'] == t].index\n",
    "        res_row[target_name] = np.mean([sdsc for _id, sdsc in sdices.items() if _id in ids_t])\n",
    "    print(res_row)\n",
    "    df_row = meta[meta['fold'] == s].iloc[0]\n",
    "    source_name = df_row['tomograph_model'] + str(df_row['tesla_value'])\n",
    "    sdices = {}\n",
    "    #for n_val in range(3):\n",
    "    #    sdices = {**sdices,\n",
    "    #              **load(path_base / f'mode_{s}/sdice_score.json')}\n",
    "    #res_row[source_name] = np.mean(list(sdices.values()))\n",
    "\n",
    "    res_row[' '] = source_name\n",
    "    records.append(res_row)\n",
    "df = pd.DataFrame.from_records(records, index=' ')\n",
    "df[df.index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-torch1.9]",
   "language": "python",
   "name": "conda-env-anaconda3-torch1.9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
